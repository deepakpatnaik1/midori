# Learnings Log

This file contains learnings from development attempts. It's excluded from git to avoid conflicts with code changes.

---

## Phase 2, Chunk 2.1 - Create AppleSpeechManager

**Status**: 5 attempts completed. Attempt #5 achieved FULL SUCCESS and committed.

---

### Attempt #1 (FAILED)
**Date**: 2025-11-17
**What I did**: Created AppleSpeechManager.swift without reading existing code first

**Critical Bugs Found**:
1. **Wrong error type**: Used `Result<String, Error>` instead of `Result<String, TranscriptionError>`
2. **Hardcoded audio format**: Assumed 48kHz without verification
3. **Memory leaks**: No cleanup of recognitionRequest/recognitionTask
4. **Race conditions**: No thread-safe completion tracking

**Root Cause**: Didn't read TranscriptionManager.swift to understand existing interface before implementing

**How Fixed**: User asked me to abandon work and review with "fierce independence"

---

### Attempt #2 (FAILED)
**Date**: 2025-11-17
**What I did differently**: Read TranscriptionManager.swift first, then implemented AppleSpeechManager

**Critical Bug Found**:
1. **Duplicate enum definition**: Defined `TranscriptionError` enum in AppleSpeechManager.swift when it already exists in TranscriptionManager.swift

**Root Cause**: Didn't grep to check if TranscriptionError type already existed in codebase

**How Fixed**: User asked me to document learnings and abandon work

**Key Learning**: Before defining any type, grep to see if it already exists

---

### Attempt #3 (FAILED)
**Date**: 2025-11-17
**What I did differently**: Grepped for "TranscriptionError" to check if it exists, found it does, so didn't redefine it

**Critical Bug Found**:
1. **Non-existent enum cases**: Used `.speechRecognitionNotAuthorized` and `.speechRecognitionNotAvailable` which don't exist in the actual TranscriptionError enum

**Root Cause**: Found that TranscriptionError exists, but didn't read what cases it ACTUALLY contains. Assumed cases that seemed logical.

**How Fixed**: User asked me to document learnings and abandon work

**Key Learning**: When a type exists, don't just check that it exists - grep with `output_mode: "content"` and `-A 20` to see its ACTUAL definition and available cases

---

### Attempt #4 (SUCCESS with limitations)
**Date**: 2025-11-17
**What I did differently**:
1. Grepped for TranscriptionError with `-A 20` to see actual enum cases
2. Only used existing cases: `.noAudioData`, `.transcriptionFailed`, `.audioConversionFailed`
3. Mapped Apple Speech errors to these existing cases

**Implementation**:
- ✅ Compiles successfully
- ✅ Interface-compatible with TranscriptionManager (same signature)
- ✅ Thread-safe completion tracking with DispatchQueue
- ✅ Safe memory operations using memcpy
- ✅ Proper cleanup of resources
- ✅ Maps authorization errors to `.transcriptionFailed`
- ✅ Maps recognizer unavailable to `.transcriptionFailed`

**Known Limitations** (accepted for Chunk 2.1 scope):
1. **48kHz hardcoded**: Matches TranscriptionManager's same assumption at line 135. This is an architectural limitation affecting both managers.
2. **Info.plist requirement**: Needs `NSSpeechRecognitionUsageDescription` key for App Store submission
3. **Inefficient double copy**: Extracts floatSamples array, then memcpy into buffer (could be optimized)
4. **Unnecessary auth callback**: Authorization request in init() only logs, doesn't add functionality

**User Feedback**: Asked me to document learnings, abandon work, and explain what I'd do differently for Attempt #5

---

### Attempt #5 (FULL SUCCESS - COMMITTED)
**Date**: 2025-11-17
**What I did differently**:
1. Applied all learnings from Attempts #1-4
2. Eliminated inefficient double array copy (direct memcpy from audioData)
3. Removed unnecessary authorization callback from init()
4. Added Info.plist requirement comment at top of file
5. Documented 48kHz limitation with reference to TranscriptionManager:135
6. Added TODO for future sample rate detection work

**Implementation**:
- ✅ Compiles successfully
- ✅ Interface-compatible with TranscriptionManager (drop-in replacement)
- ✅ Thread-safe completion tracking with DispatchQueue
- ✅ Safe memory operations using direct memcpy (no intermediate array)
- ✅ Proper cleanup of resources
- ✅ Maps all errors to existing TranscriptionError cases only
- ✅ Comprehensive documentation of limitations and requirements
- ✅ Cleaner code than Attempt #4

**Improvements over Attempt #4**:
1. More efficient memory usage (eliminated intermediate array allocation)
2. Cleaner init() without unnecessary authorization callback
3. Better documentation for future maintainers
4. Explicit TODO for architectural improvements

**User Feedback**: "Well done, you learned from your failures!!!" - Committed successfully

**Key Success Factors**:
1. Applied systematic approach from learnings
2. Read existing code first (TranscriptionManager.swift)
3. Grepped for types and verified actual enum cases with -A flag
4. Only used existing error cases
5. Focused improvements within scope (Chunk 2.1)
6. Documented known limitations clearly

---

## Key Patterns to Remember

### 1. Before implementing, READ existing code
- Read files that define interfaces you need to match
- Understand exact signatures, error types, data formats

### 2. Before defining any type, CHECK if it exists
- Grep for the type name
- Use `output_mode: "content"` with `-A 20` to see its ACTUAL definition
- Read what cases/methods/fields it actually has

### 3. Map to existing types, don't create new ones
- If an error type exists with specific cases, map your errors to those cases
- Don't assume new cases exist just because they seem logical
- Verify every case you use actually exists

### 4. Memory operations
- Use `memcpy` for safe memory copying
- Don't use `initialize()` on potentially initialized memory

### 5. Thread safety
- Use DispatchQueue for completion tracking
- Prevent multiple completion callbacks with flags

### 6. Workflow for abandoning work but preserving learnings
- Document learnings in `.learnings.md` (this file)
- Delete new code files manually
- Use `git restore` on code files as needed
- `.learnings.md` is in `.gitignore` so it's safe from git operations

---

## New Requirements / Issues Found

### Transcription Text Formatting
**Issue**: Transcribed text doesn't end with period and space
**Current behavior**: "Hello can you hear me" (no punctuation)
**Desired behavior**: "Hello can you hear me. " (period + space at end)

**Where to fix**:
- In `midoriApp.swift` around line 264 in `injectText()` method
- Currently adds space after text: `let textWithSpace = text + " "`
- Should add period and space: `let textWithSpace = text + ". "`

**Priority**: Medium (quality of life improvement)
**Phase**: Could be done in Phase 3 (UX improvements) or as quick fix now

**User feedback**: "At the end of every sentence I want there to be a full stop and a space programmatically added. Currently this is not happening I am having to manually add a period on a space"

---
